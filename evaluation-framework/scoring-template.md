# Evaluation: [Use Case Name]

## Evaluator Info

- **Name**:
- **Date**:
- **Use Case**: [link to use case file]
- **Domain**: Developer / Data Science

## Setup

- **Claude Code version**:
- **Copilot version/tier**:
- **IDE**:
- **Language/Framework**:
- **OS**:
- **Relevant extensions/plugins**:

## Task Description

_Brief description of what you were trying to accomplish:_

## Scorecard

| Metric | Claude Code (1-5) | Copilot (1-5) | Notes |
|--------|-------------------|---------------|-------|
| Speed | | | |
| Accuracy | | | |
| Code Quality | | | |
| Context Understanding | | | |
| Iteration Efficiency | | | |
| Autonomy | | | |
| Scope of Capability | | | |
| Domain Fit | | | |
| **Total** | **/40** | **/40** | |

## Timing

| Measurement | Claude Code | Copilot |
|-------------|-------------|---------|
| Time to first useful output | | |
| Total time to completion | | |
| Number of prompts/interactions | | |

## Detailed Observations

### Claude Code

**What worked well:**

-

**What didn't work well:**

-

**Notable code snippet (good or bad):**

```
# paste relevant code here
```

### GitHub Copilot

**What worked well:**

-

**What didn't work well:**

-

**Notable code snippet (good or bad):**

```
# paste relevant code here
```

## Head-to-Head Comparison

_For this specific task, which tool did you prefer and why?_

## Key Takeaways

_What did you learn? Any surprises? Would you use one tool over the other for this type of task going forward?_
